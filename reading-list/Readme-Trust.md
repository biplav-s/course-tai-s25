<em> **See also** : 
readings in [Large Language Models (LLMs)](https://github.com/biplav-s/course-tai-s25/blob/main/reading-list/Readme-LLMs.md) and [AI and NLP](https://github.com/biplav-s/course-tai-s25/blob/main/reading-list/Readme-AI-NLP.md) </em>

---

## Books and Tutorials
* [Trustworthy Machine Learning](http://www.trustworthymachinelearning.com/), by Kush Varshney, 2022.
* Tutorial on [Evaluating and Rating AI Systems for Trust and Its Application to Finance](https://sites.google.com/view/raasta2024icaif), Kausik Lakkaraju, Rachneet Kaur, Sunandita Patra, Biplav Srivastava, 5th ACM International Conference on AI in Finance (ICAIF-24), New York, USA, Nov 2024.
* Tutorial on [Trusting AI by Testing and Rating Third Party Offerings](https://sites.google.com/view/ijcai2020tut-aitrust/home), in conjunction with 29th International Joint Conference on Artificial Intelligence (IJCAI 2020), Biplav Srivastava, Francesca Rossi, Yokohoma, Japan, Jan 2021.
* NIST Taxonomy and Terminology of [Attacks and Mitigations of Adverserial Machine Learning](https://nvlpubs.nist.gov/nistpubs/ai/NIST.AI.100-2e2025.pdf), March 2025

## Papers
* Sahil Verma and Julia Rubin. 2018. [Fairness definitions explained](https://fairware.cs.umass.edu/papers/Verma.pdf). In Proceedings of the International Workshop on Software Fairness (FairWare '18). Association for Computing Machinery, New York, NY, USA, 1–7. [**Explains fairness definitions using German-credit data**].
* Joy Buolamwini, Timnit Gebru. [Gender Shades: Intersectional Accuracy Disparities in Commercial Gender Classification](https://proceedings.mlr.press/v81/buolamwini18a.html). In Sorelle A. Friedler, Christo Wilson, editors, Conference on Fairness, Accountability and Transparency, FAT 2018, 23-24 February 2018, New York, NY, USA. Volume 81 of Proceedings of Machine Learning Research, pages 77-91, PMLR, 2018. [**Discusses bias in AI doing face recognition**]
* Tolga Bolukbasi, Kai-Wei Chang, James Zou, Venkatesh Saligrama, and Adam Kalai. 2016. [Man is to computer programmer as woman is to homemaker? debiasing word embeddings](https://proceedings.neurips.cc/paper_files/paper/2016/file/a486cd07e4ac3d270571622f4f316ec5-Paper.pdf). In Proceedings of the 30th International Conference on Neural Information Processing Systems (NIPS'16). Curran Associates Inc., Red Hook, NY, USA, 4356–4364. [**Discusses bias in NLP/ word embeddings**]
* Tim Miller. 2023. [Explainable AI is Dead, Long Live Explainable AI! Hypothesis-driven Decision Support using Evaluative AI](https://dl.acm.org/doi/10.1145/3593013.3594001). In Proceedings of the 2023 ACM Conference on Fairness, Accountability, and Transparency (FAccT '23). Association for Computing Machinery, New York, NY, USA, 333–342. [**Argues why explainability should support evidence for all interpretations, and let the user decide**]

## Domain Specific 
* **Elections**: LLM-based AI were missing in action for 2024
  > - See PROMISE team's work on [AI and elections](https://sites.google.com/site/biplavsrivastava/research-1/ai-and-elections), 2021- 
  > - OpenAI's [avoidance of the challenge for 2024 elections around the world](https://openai.com/index/how-openai-is-approaching-2024-worldwide-elections/)
  > - Beyond ChatGPT, others were not better. See Rozado, D. 2024. [The Political Preferences of LLMs](https://journals.plos.org/plosone/article?id=10.1371/journal.pone.0306621), arXiv:2402.01789.
  > - Understanding and predicting elections, [IISER, Pune](https://electioninsights.in/)
  >> - Key insights and tools to [play with results](https://electioninsights.in/insights.html)
  >> - Details are in [papers](https://electioninsights.in/publications.html). Suggest starting from [news article](http://sites.iiserpune.ac.in/~santh/thehindu_elections_mss.png) (Jan 2025)

